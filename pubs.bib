@article {Agarwal2020Bombalytics,
    type = {Full Paper},
	title = {Bombalytics: Visualization of Competition and Collaboration Strategies of Players in a Bomb Laying Game},
	pages = {89--100},
	journal = {Computer Graphics Forum},
	volume = {39},
	number = {3},
	issn = {1467-8659},
	doi = {doi:10.1111/cgf.13965},
	abstract = {Competition and collaboration form complex interaction patterns between the agents and objects involved. Only by understanding these interaction patterns, we can reveal the strategies the participating parties applied. In this paper, we study such competition and collaboration behavior for a computer game. Serving as a testbed for artificial intelligence, the multiplayer bomb laying game Pommerman provides a rich source of advanced behavior of computer agents. We propose a visualization approach that shows an overview of multiple games, with a detailed timeline-based visualization for exploring the specifics of each game. Since an analyst can only fully understand the data when considering the direct and indirect interactions between agents, we suggest various visual encodings of these interactions. Based on feedback from expert users and an application example, we demonstrate that the approach helps identify central competition strategies and provides insights on collaboration.},
	url = {https://dx.doi.org/doi:10.1111/cgf.13965},
	year = {2020},
	month = {may},
	author = {Agarwal, Shivam and Wallner, Günter and Beck, Fabian},
	paperurl = {Agarwal2020Bombalytics.pdf},
    video = {https://www.youtube.com/watch?v=PpswyIDFAeg},
    image = {Agarwal2020Bombalytics.PNG},
    demo = {https://vis-uni-bamberg.github.io/bombalytics/},
    code = {https://osf.io/2vxh4/},
    github = {https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/bombalytics},
    blogpost = {Agarwal2020Bombalytics.md},
    awards = {NeurIPS 2019 Flatland Competition},
    shorturl = {bombalytics}
}

@article {Agarwal2020SetStreams,
    type = {Full Paper},
	title = {{Set Streams}: Visual Exploration of Dynamic Overlapping Sets},
	journal = {Computer Graphics Forum},
	volume = {39},
	number = {3},
	pages = {383-391},
	issn = {1467-8659},
	doi = {doi:10.1111/cgf.13988},
	abstract = {In many applications, membership of set elements changes over time. Since each element can be present in multiple sets, the sets also overlap. As a result, it becomes challenging to visualize the temporal change in set membership of elements across several timesteps while showing individual set intersections. We propose Set Streams, a visualization technique that represents changing set structures on a timeline as branching and merging streams. The streams encode the changing membership of elements with set intersections. A query-based selection mechanism supports a flexible comparison of selected groups of elements across the temporal evolution. The main timeline view is complemented with additional panels to provide details about the elements. While the proposed visualization is an application-independent visualization technique for dynamic sets, we demonstrate its effectiveness and applicability through three diverse application examples and expert feedback.},
	keywords = {Dynamic sets, streams, set visualization},
	url = {https://dx.doi.org/doi:10.1111/cgf.13988},
	year = {2020},
	month = {may},
	author = {Agarwal, Shivam and Beck, Fabian},
	paperurl = {Agarwal2020SetStreams.pdf},
    video = {https://www.youtube.com/watch?v=Un0GUCn-H7c},
    image = {Agarwal2020SetStreams.PNG},
    code = {https://osf.io/86bkj/},
    demo = {https://vis-uni-bamberg.github.io/setstreams/},
    github = {https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/setstreams},
    shorturl = {setstreams}
}

@article{Krause2023Visually,
    author = {Krause, Cedric and Agarwal, Shivam and Burch, Michael and Beck, Fabian},
    title = {Visually Abstracting Event Sequences as Double Trees Enriched with Category-Based Comparison},
    journal = {Computer Graphics Forum},
    volume = {42},
    number = {6},
    pages = {},
    year = {2023},
    keywords = {Visualization, Information Visualization},
    doi = {10.1111/cgf.14805},
    abstract = {Abstract Event sequence visualization aids analysts in many domains to better understand and infer new insights from event data. Analysing behaviour before or after a certain event of interest is a common task in many scenarios. In this paper, we introduce, formally define, and position double trees as a domain-agnostic tree visualization approach for this task. The visualization shows the sequences that led to the event of interest as a tree on the left, and those that followed on the right. Moreover, our approach enables users to create selections based on event attributes to interactively compare the events and sequences along colour-coded categories. We integrate the double tree and category-based comparison into a user interface for event sequence analysis. In three application examples, we show a diverse set of scenarios, covering short and long time spans, non-spatial and spatial events, human and artificial actors, to demonstrate the general applicability of the approach.},
    paperurl = {Krause2023Visually.pdf},
    image = {Krause2023Visually.PNG},
    demo = {https://vis-uni-bamberg.github.io/doubletrees/},
    github = {https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/doubletrees}

}

@article{Liebers2023Viscomet,
    title={{VisCoMET:} Visually Analyzing Team Collaboration in Medical Emergency Trainings},
    author={Liebers, Carina and Agarwal, Shivam and Krug, Maximilian and Pitsch, Karola and Beck, Fabian},
    abstract = {Handling emergencies requires efficient and effective collaboration of medical professionals. To analyze their performance, in an application study, we have developed VisCoMET, a visual analytics approach displaying interactions of healthcare personnel in a triage training of a mass casualty incident. The application scenario stems from social interaction research, where the collaboration of teams is studied from different perspectives. We integrate recorded annotations from multiple sources, such as recorded videos of the sessions, transcribed communication, and eye-tracking information. For each session, an information-rich timeline visualizes events across these different channels, specifically highlighting interactions between the team members. We provide algorithmic support to identify frequent event patterns and to search for user-defined event sequences. Comparing different teams, an overview visualization aggregates each training session in a visual glyph as a node, connected to similar sessions through edges. An application example shows the usage of the approach in the comparative analysis of triage training sessions, where multiple teams encountered the same scene, and highlights discovered insights. The approach was evaluated through feedback from visualization and social interaction experts. The results show that the approach supports reflecting on teams performance by exploratory analysis of collaboration behavior while particularly enabling the comparison of triage training sessions.},
    journal = {Computer Graphics Forum},
    volume = {42},
    number = {3},
    pages = {149-160},
    year={2023},
    ISSN = {1467-8659},
    doi = {10.1111/cgf.14819},
    paperurl = {Liebers2023Viscomet.pdf},
    image = {Liebers2023Viscomet.PNG}
}

@inproceedings{Agarwal2017Nodetrix, 
	author= {Agarwal, Shivam and Tomar, Amit and Sreevalsan-Nair, Jaya}, 
	title= {{NodeTrix-Multiplex}: Visual Analytics of Multiplex Small World Networks}, 
	booktitle= {Complex Networks & Their Applications}, 
	year= {2017}, 
	publisher= {Springer International Publishing}, 
	pages= {579--591}, 
	abstract= {Analyzing multiplex small world networks (SWNs) using community detection (CD) is a challenging task. We propose the use of visual analytics to probe and extract communities in such networks, where one of the layers defines the network topology and exhibits small-world property. Our novel visual analytics framework, NodeTrix-Multiplex (NTM), for visual exploration of multiplex SWNs, integrates focus+context network visualization, and analysis of community detection results, within the focus. We propose a heterogeneous data model, which composites multiple layers for the focus and context and thus, enables finding communities across layers. We perform a case-study on a co-authorship (collaboration) network, with a functional layer obtained from the author-topic similarity graph. We also perform an expert user evaluation of the tool, developed using NTM.}, 
	isbn= {978-3-319-50901-3},
    doi = {10.1007/978-3-319-50901-3_46},
    paperurl = {Agarwal2017Nodetrix.pdf},
    image = {Agarwal2017Nodetrix.PNG},
    demo = {https://nodetrix-multiplex.vercel.app/}
}

@conference{Nair2017Nodetrix,
	author={Sreevalsan-Nair, Jaya and Agarwal, Shivam},
	title={{NodeTrix-CommunityHierarchy}: Techniques for Finding Hierarchical Communities for Visual Analytics of Small-world Networks},
	booktitle={12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 3: IVAPP, (VISIGRAPP 2017)},
	abstract = {While there are several visualizations of the small world networks (SWN), how does one find an appropriate set of visualizations and data analytic processes in a data science workflow? Hierarchical communities in SWN aid in managing and understanding the complex network better. To enable a visual analytics workflow to probe and uncover hierarchical communities, we propose to use both the network data and metadata (e.g. node and link attributes). Hence, we propose to use the network topology and node-similarity graph using metadata, for knowledge discovery. For the construction of a four-level hierarchy, we detect communities on both the network and the similarity graph, by using specific community detection at specific hierarchical level. We enable the flexibility of finding non-overlapping or overlapping communities, as leaf nodes, by using spectral clustering. We propose NodeTrix-CommunityHierarchy (NTCH), a set of visual analytic techniques for hierarchy construction, visual explo ration and quantitative analysis of community detection results. We extend NodeTrix-Multiplex framework (Agarwal et al., 2017), which is for visual analytics of multilayer SWN, to probe hierarchical communities. We propose novel visualizations of overlapping and non-overlapping communities, which are integrated into the framework. We show preliminary results of our case-study of using NTCH on co-authorship networks.},
    year={2017},
	pages={140-151},
	publisher={SciTePress},
	organization={INSTICC},
	doi={10.5220/0006175701400151},
	isbn={978-989-758-228-8},
    paperurl = {Nair2017Nodetrix.pdf},
}

@conference{Lukose2018Design,
	author={Lukose, Kuruvilla and Agarwal, Shivam and Rao, Vidyashankar Nagesha and Sreevalsan-Nair, Jaya},
	title={Design Study for Creating {Pathfinder}: A Visualization Tool for Generating Software Test Plans using Model based Testing},
	booktitle={13th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - Volume 2: IVAPP,},
    abstract = {Model Based Testing (MBT) is a popularly used software testing technique in the software industry. However, there still exists a gap between the awareness of benefits of MBT and its adoption in the industry, specifically in the Computer Aided Design (CAD) or Computer Aided Engineering (CAE) domains. This can be predominantly attributed to the learning curve of using many of the existing MBT tools. To address this gap in the CAD/CAE industry, we propose Pathfinder - an MBT tool, with a Graphical User Interface (GUI), for guiding a software tester in generating test plans for a system-under-test (SUT). The goal of using Pathfinder is for obtaining consistency and reproducibility in the generated test plans across a team of software testers. Our tool introduces a novel representation of the SUT as a High-level Model (HLM), and the use of graph visualization for test plan generation from the HLM. We have designed the GUI to be intuitive for the tester to generate test plans and select re levant tests, which precedes the test execution done outside of our tool. Here, we discuss the design decisions we adopted towards creating Pathfinder, and demonstrates its usage with two case studies.},
	year={2018},
	pages={289-300},
	publisher={SciTePress},
	organization={INSTICC},
	doi={10.5220/0006622302890300},
	isbn={978-989-758-289-9},
    paperurl = {Lukose2018Design.pdf},
    video = {https://www.youtube.com/watch?v=mgjdDZtmgfQ},
    image = {Lukose2018Design.png}
}

@inproceedings{Sreevalsan2017Collaborative,
    type = {Poster},
    title={Collaborative Design of Visual Analytic Techniques for Survey Data for Community-based Research in Public Health},
    author={Sreevalsan-Nair, Jaya and Agarwal, Shivam and Vangimalla, Reddy Rani and Ramesh, Sanat and Murthy, Nirmala},
    booktitle={8th Workshop of Visual Analytics in Healthcare (VAHC)},
    abstract = {Visual analytics is widely adopted in iterative data science/analytic workflows where the human-in-the-loop uses the visualizations to make sense of the data. We are interested in the in-depth analysis of the surveys conducted for studying the effectiveness of public health programs, for which we propose the use of visual analytics. Here, a collaboration between researchers in public health and visualization has led to co-creation of workflows enabling visual analytic techniques for subject-centric raw data from the surveys. We build an appropriate data model which feeds into our proposed visualization techniques. We present a prototype implementation of our tool, SurveyVis, and demonstrate the usage of our tool in analyzing a public health program deployed in India.},
    pages={1--2},
    year={2017},
    paperurl = {Sreevalsan2017Collaborative.pdf},
}

@inproceedings {Agarwal2018Computer,
	title = {Computer-supported Interactive Assignment of Keywords for Literature Collections},
	booktitle = {IEEE VIS Workshop on Machine Learning from User Interaction for Visualization and Analytics},
	abstract = {A curated literature collection on a specific topic helps researchers to find relevant articles quickly. Assigning multiple keywords to each article is one of the techniques to structure such a collection. But it is challenging to assign all the keywords consistently without any gaps or ambiguities. We propose to support the user with a machine learning technique that suggests keywords for articles in a literature collection browser. We provide visual explanations to make the keyword suggestions transparent. The suggestions are based on previous keyword assignments. The machine learning technique learns on the fly from the interactive assignments of the user. We seamlessly integrate the proposed technique in an existing literature collection browser and investigate various usage scenarios through an early prototype.},
	year = {2018},
	month = {oct},
	author = {Agarwal, Shivam and Bernard, Jürgen and Beck, Fabian},
	paperurl = {Agarwal2018Computer.pdf},
    image = {Agarwal2018Computer.PNG}
}

@inproceedings {Agarwal2020Visualizing,
    type = {Short Paper},
	title = {Visualizing {AI} Playtesting Data of 2D Side-scrolling Games},
	booktitle = {IEEE Conference on Games},
	journal = {IEEE Conference on Games (CoG)},
	abstract = {Human playtesting is a useful step in the game development process, but involves high economic costs and is time-consuming. While playtesting through artificial intelligence is gaining attention, it is challenging to analyze the collected data. We address the challenge by proposing visualizations to derive insights about level design in 2D side-scrolling games. To focus on the navigation behavior in the level design, we study the trajectories of computer agents trained using artificial intelligence. We demonstrate the effectiveness of our approach by implementing a web-based prototype and presenting the insights gained from the visualizations for the game Sonic the Hedgehog 2. We highlight lessons learned and directions to customize the approach for other analysis goals of playtesting.},
	keywords = {artificial intelligence, playtesting, visualization},
	year = {2020},
	month = {aug},
	author = {Agarwal, Shivam and Herrmann, Christian and Wallner, Günter and Beck, Fabian},
	pages = {572-575},
	doi = {10.1109/CoG47356.2020.9231915},
	paperurl = {Agarwal2020Visualizing.pdf},
    video = {https://www.youtube.com/watch?v=H6q7kLKfqRw},
    image = {Agarwal2020Visualizing.PNG}
}

@inproceedings {Agarwal2020Design,
    type = {Full Paper},
	title = {A Design and Application Space for Visualizing User Sessions of Virtual and Mixed Reality Environments},
	booktitle = {Vision, Modeling, and Visualization},
	doi = {doi:10.2312/vmv.20201194},
	abstract = {Virtual and mixed reality environments gain complexity due to the inclusion of multiple users and physical objects. A core challenge for developers and researchers while analyzing sessions from such environments lies in understanding the interaction between entities. Additionally, the raw data recorded from such sessions is difficult to analyze due to the simultaneous temporal and spatial changes of multiple entities. However, similar data has already been visualized in other areas of application. We analyze which aspects of these related visualizations can be leveraged for analyzing user sessions in virtual and mixed reality environments and describe a design and application space for such visualizations. First, we examine what information is typically generated in interactive virtual and mixed reality applications and how it can be analyzed through such visualizations. Next, we study visualizations from related research fields and derive seven visualization categories. These categories act as building blocks of the design space, which can be combined into specific visualization systems. We also discuss the application space for these visualizations in debugging and evaluation scenarios. We present two application examples that showcase how one can visualize virtual and mixed reality user sessions and derive useful insights from them.},
	url = {https://dx.doi.org/doi:10.2312/vmv.20201194},
	year = {2020},
	month = {sep},
	author = {Agarwal, Shivam and Auda, Jonas and Schneegaß, Stefan and Beck, Fabian},
	paperurl = {Agarwal2020Design.pdf},
    video = {https://www.youtube.com/watch?v=hUenXnU5Adk},
    image = {Agarwal2020Design.PNG},
    demo = {https://vis-uni-bamberg.github.io/vr_mr_vis/},
    code = {https://osf.io/2hstc/},
    github = {https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/vr_mr_vis},
    shorturl = {mrsessions}
}

@inproceedings {Agarwal2020VisualizingSets,
    type = {Full Paper},
	title = {Visualizing Sets and Changes in Membership Using Layered Set Intersection Graphs},
	booktitle = {Vision, Modeling, and Visualization},
	doi = {doi:10.2312/vmv.20201189},
	abstract = {Challenges in set visualization include representing overlaps among sets, changes in their membership, and details of constituent elements. We present a visualization technique that addresses these challenges. The approach uses set intersection graphs that explicitly visualize each set intersection as a rectangular node and elements as circles inside them. We represent the graph as a layered node-link diagram using colors to indicate the sets. The layers reflect different levels of intersections, from the base sets in the lowest layer to potentially the intersection of all sets in the highest layer. We provide different perspectives to show temporal changes in set membership. Graphs for individual, two, and all timesteps are visualized in static, diff, and aggregated views. Together with linked views and filters, the technique supports the detailed exploration of dynamic set data. We demonstrate the effectiveness of the proposed approach by discussing two application examples. The submitted supplemental material contains a video showing proposed interactions in the implementation and the prototype itself.},
	url = {https://dx.doi.org/doi:10.2312/vmv.20201189},
	year = {2020},
	month = {sep},
	author = {Agarwal, Shivam and Tkachev, Gleb and Wermelinger, Michel and Beck, Fabian},
	paperurl = {Agarwal2020VisualizingSets.pdf},
    image = {Agarwal2020VisualizingSets.PNG},
    demo = {https://vis-uni-bamberg.github.io/dsv/},
    code = {https://osf.io/3nd9h/},
    video = {https://www.youtube.com/watch?v=hG_ioaZ2DEg},
    github = {https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/dsv},
    awards = {Best Paper Award at VMV},
    shorturl = {dynamicsets}
}

@inproceedings {Agarwal2020How,
	title = {How Visualization PhD Students Cope with Paper Rejections},
	booktitle={IEEE VIS workshop on Celebrating the Scientific Value of Failure (FailFest)}, 
	  year={2020},
	  volume={},
	  number={},
	  pages={6-10},
	  doi={10.1109/FailFest51498.2020.00006},
	abstract = {We conducted a questionnaire study aimed towards PhD students in the field of visualization research to understand how they cope with paper rejections. We collected responses from 24 participants and performed a qualitative analysis of the data in relation to the provided support by collaborators, resubmission strategies, handling multiple rejects, and personal impression of the reviews. The results indicate that the PhD students in the visualization community generally cope well with the negative reviews and, with experience, learn how to act accordingly to improve and resubmit their work. Our results reveal the main coping strategies that can be applied for constructively handling rejected visualization papers. The most prominent strategies include: discussing reviews with collaborators and making a resubmission plan, doing a major revision to improve the work, shortening the work, and seeing rejection as a positive learning experience.},
	author = {Agarwal, Shivam and Latif, Shahid and Beck, Fabian},
	paperurl = {Agarwal2020How.pdf},
    video = {https://www.youtube.com/watch?v=YLQFBNQAEFI},
    image = {Agarwal2020How.PNG},
    code = {https://osf.io/vgj36/}
}

@inproceedings {Krause2021Visual,
    type = {Full Paper},
	author = {Krause, Cedric and Agarwal, Shivam and Ghoniem, Mohammad and Beck, Fabian},
	title = {Visual Comparison of Multi-label Classification Results},
	booktitle = {Vision, Modeling, and Visualization},
	doi = {doi:10.2312/vmv.20211367},
	year = {2021},
	paperurl = {Krause2021Visual.pdf},
	abstract = {In multi-label classification, we do not only want to analyze individual data items but also the relationships between the assigned labels. Employing different sources and algorithms, the label assignments differ. We need to understand these differences to identify shared and conflicting assignments. We propose a visualization technique that addresses these challenges. In graphs, we present the labels for any classification result as nodes and the pairwise overlaps of labels as links between them. These graphs are juxtaposed for the different results and can be diffed graphically. Clustering techniques are used to further analyze similarities between labels or classification results, respectively. We demonstrate our prototype in two application examples from the machine learning domain.},
    image = {Krause2021Visual.PNG},
    video = {https://www.youtube.com/watch?v=Jut9xVr3jsk}
}

@inproceedings {Latif2021Visually,
    type = {Short Paper},
	author = {Latif, Shahid and Agarwal, Shivam and Gottschalk, Simon and Chrosch, Carina and Feit, Felix and Jahn, Johannes and Braun, Tobias and Tchenko, Yannick Christian and Demidova, Elena and Beck, Fabian},
	title = {Visually Connecting Historical Figures Through Event Knowledge Graphs},
	booktitle = {IEEE VIS},
    doi = {10.1109/VIS49827.2021.9623313},
    pages = {156-160},
	publisher = {IEEE},
	year = {2021},
	paperurl = {Latif2021Visually.pdf},
	abstract = {Knowledge graphs store information about historical figures and their relationships indirectly through shared events. We developed a visualization system, VisKonnect, for analyzing the intertwined lives of historical figures based on the events they participated in. A user’s query is parsed for identifying named entities, and related data is retrieved from an event knowledge graph. While a short textual answer to the query is generated using the GPT-3 language model, various linked visualizations provide context, display additional information related to the query, and allow exploration.},
    image = {Latif2021Visually.PNG},
    video = {https://www.youtube.com/watch?v=FG69qFHicYE}
}

@inproceedings{Laurent2021Flatland,
  title = 	 {Flatland Competition 2020: {MAPF} and {MARL} for Efficient Train Coordination on a Grid World},
  author =       {Laurent, Florian and Schneider, Manuel and Scheller, Christian and Watson, Jeremy and Li, Jiaoyang and Chen, Zhe and Zheng, Yi and Chan, Shao-Hung and Makhnev, Konstantin and Svidchenko, Oleg and Egorov, Vladimir and Ivanov, Dmitry and Shpilman, Aleksei and Spirovska, Evgenija and Tanevski, Oliver and Nikov, Aleksandar and Grunder, Ramon and Galevski, David and Mitrovski, Jakov and Sartoretti, Guillaume and Luo, Zhiyao and Damani, Mehul and Bhattacharya, Nilabha and Agarwal, Shivam and Egli, Adrian and Nygren, Erik and Mohanty, Sharada},
  booktitle = 	 {NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {275--301},
  year = 	 {2021},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  publisher =    {PMLR},
  abstract = 	 {The Flatland competition aimed at finding novel approaches to solve the vehicle re-scheduling problem (VRSP). The VRSP is concerned with scheduling trips in traffic networks and the re-scheduling of vehicles when disruptions occur, for example the breakdown of a vehicle. While solving the VRSP in various settings has been an active area in operations research (OR) for decades, the ever-growing complexity of modern railway networks makes dynamic real-time scheduling of traffic virtually impossible. Recently, multi-agent reinforcement learning (MARL) has successfully tackled challenging tasks where many agents need to be coordinated, such as multiplayer video games. However, the coordination of hundreds of agents in a real-life setting like a railway network remains challenging and the Flatland environment used for the competition models these real-world properties in a simplified manner. Submissions had to bring as many trains (agents) to their target stations in as little time as possible. While the best submissions were in the OR category, participants found many promising MARL approaches. Using both centralized and decentralized learning based approaches, top submissions used graph representations of the environment to construct tree-based observations. Further, different coordination mechanisms were implemented, such as communication and prioritization between agents. This paper presents the competition setup, four outstanding solutions to the competition, and a cross-comparison between them.	},
  paperurl = {Laurent2021Flatland.pdf}

}

@inproceedings{Agarwal2022Spatio,
    type = {Full Paper},
    title = {Spatio-temporal Analysis of Multi-agent Scheduling Behaviors on Fixed-track Networks},
    abstract = {Multi-agent systems require coordination among the agents to solve a given task. For movement on fixed-track networks, traditional scheduling algorithms have dominated so far, but the interest in autonomous and intelligent agents is growing as they promise to react to unexpected and exceptional situations more robustly. In this paper, we study data from the Flatland 2020 NeurIPS Competition, where trains move through a virtual rail network. We developed a timeline-based visualization that provides an overview of all train movements in a simulated episode, clearly hinting at different phases, non-optimal routes, and issues such as deadlocks. This view is complemented with a map view and a graph view, interactively linked through highlighting and synchronous animation. Defining regions of interest in the map builds an analysis graph for detailed inspection. A comparison mode allows contrasting two different episodes regarding the same rail network across all views. We have conducted this application study in close collaboration with the Flatland community. Identified analysis goals stem from interviews with key persons of the community, while the approach itself was developed in two iterations based on feedback from experts with diverse backgrounds. This feedback, together with an analysis of the winning submissions from the competition, confirms that the initial analysis goals can be answered.},
	year = {2022},
	author = {Agarwal, Shivam and Wallner, Günter and Watson, Jeremy and Beck, Fabian},
    booktitle={IEEE Pacific Visualization Symposium (PacificVis)}, 
    doi = {10.1109/PacificVis53943.2022.00011},
    pages={21-30},
    ISSN={2165-8773},
    paperurl = {Agarwal2022Spatio.pdf},
    image = {Agarwal2022Spatio.PNG},
    demo = {https://vis-uni-bamberg.github.io/fv/},
    code = {https://osf.io/R2YZA/},
    video = {https://www.youtube.com/watch?v=olQw9bw2KR4},
    github = {https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/fv},
    awards = {NeurIPS 2020 Flatland Competition},
    shorturl = {fv}
}

@inproceedings{Agarwal2022CiteVis,
    type = {Poster},
    author={Agarwal, Shivam and Ghosh, Uttiya and Beck, Fabian and Sreevalsan-Nair, Jaya},
    booktitle={IEEE Pacific Visualization Symposium ({PacificVis} - Poster)}, 
    title={{CiteVis}: Visual Analysis of Overlapping Citation Intents as Dynamic Sets}, 
    abstract={A scientific article can be cited with different intents over several years. The citation intents can be inferred by classifying the citation text into different categories. With multiple citations to the same article, the citation intent categories overlap, making their analysis more challenging. We model the categories as dynamic sets and propose an approach to visualize temporal citation trends of an article across overlapping citation intents. The approach supports comparison between the citation trends of two seed articles of interest. The implemented prototype supports searching and selecting seed articles from a Semantic Scholar dataset.},
    year={2022},
    paperurl = {Agarwal2022CiteVis.pdf},
    poster = {Agarwal2022CiteVis_Poster.pdf},
    image = {Agarwal2022CiteVis.PNG},
    demo = {https://vis-uni-bamberg.github.io/citevis/},
    video = {https://www.youtube.com/watch?v=NUtGWdCgTzM},
    github = {https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/citevis},
    shorturl = {citevis}
}

@inproceedings{Agarwal2022Visualizing,
    type = {Poster},
    author={Agarwal, Shivam and Latif, Shahid and Rothweiler, Aristide and Beck, Fabian},
    booktitle={{EuroVis} - Poster}, 
    title={Visualizing the Evolution of Multi-agent Game-playing Behaviors}, 
    abstract={Analyzing the training evolution of AI agents in a multi-agent environment helps to understand changes in learned behaviors, as well as the sequence in which they are learned. We train an existing Pommerman team from scratch and, at regular intervals, let it battle against another top-performing team. We define thirteen game-specific behaviors and compute their occurrences in 600 matches. To investigate the evolution of these behaviors, we propose a visualization approach and showcase its usefulness in an application example.},
    year={2022},
    paperurl = {Agarwal2022Visualizing.pdf},
    poster = {Agarwal2022Visualizing_Poster.pdf},
    image = {Agarwal2022Visualizing.png},
    code = {https://github.com/s-agarwl/EvolvingAI},
    demo = {https://evolving-ai.vercel.app/},
    video = {https://www.youtube.com/watch?v=L4hXKtc-VaU},
    ISBN = {978-3-03868-185-4},
    doi = {10.2312/evp.20221111},
    shorturl = {evolvingai}
}

@inproceedings{Agarwal2023Visualizing,
    author = {Agarwal, Shivam},
    booktitle = {{EuroVis} - Short Paper},
    title = {Visualizing Element Interactions in Dynamic Overlapping Sets},
    abstract = {Elements---the members in sets---may change their memberships over time. Moreover, elements also directly interact with each other, indicating an explicit connection between them. Visualizing both together becomes challenging. Using an existing dynamic set visualization as a basis, we propose an approach to encode the interactions of elements together with changing memberships in sets. We showcase the value in visually analyzing both aspects of elements together through two application examples. The first example shows the evolution of business portfolio and interactions (e.g., acquisitions and partnerships) among companies. A second example analyzes the dynamic collaborative interactions among researchers in computer science.},
    year = {2023},
    ISBN = {978-3-03868-219-6},
    doi = {10.2312/evs.20231050},
    paperurl = {Agarwal2023Visualizing.pdf},
    image = {Agarwal2023Visualizing.PNG},
    code = {https://github.com/s-agarwl/sets_interactions},
    demo = {https://setsinteractions.vercel.app/},
    video = {https://youtu.be/D8DQniBkwgY},
    shorturl = {sets_interactions}
}

@inproceedings {Liebers2023CohExplore,
    type = {Poster},
    booktitle = {{EuroVis} - Poster},
    title = {{CohExplore: Visually Supporting Students in Exploring Text Cohesion}},
    abstract = {A cohesive text allows readers to follow the described ideas and events. Exploring cohesion in text might aid students enhancing their academic writing. We introduce CohExplore, which promotes exploring and reflecting on cohesion of a given text by visualizing computed cohesion-related metrics on an overview and detailed level. Detected topics are color-coded, semantic similarity is shown via lines, while connectives and co-references in a paragraph are encoded using text decoration. Demonstrating the system, we share insights about a student-authored text.},
    author = {Liebers, Carina and Agarwal, Shivam and Beck, Fabian},
    year = {2023},
    publisher = {The Eurographics Association},
    ISBN = {978-3-03868-220-2},
    doi = {10.2312/evp.20231058},
    paperurl = {Liebers2023CohExplore.pdf},
    poster = {Liebers2023CohExplore_Poster.pdf},
    image = {Liebers2023CohExplore.PNG}
}

@inproceedings{Pron2024Comparative,
    booktitle = {{EuroVis} - Short Papers},
    title = {Comparative Analysis of Timeline-based Visualizations for Dynamic Overlapping Sets},
    abstract = {Timeline-based set visualizations provide an overview of how overlapping categorical data evolves. We study three different visualization techniques of such type and made minor modifications to visualize the same data in a two-fold comparison. First, we contrast their encodings and interactions through a conceptual analysis. Second, in a user study with 28 participants, we evaluate their performance regarding different analysis tasks for dynamic sets and record user feedback along various dimensions.},
    author = {Pron, Mariana and Agarwal, Shivam and Poddar, Madhav and Beck, Fabian},
    year = {2024},
    publisher = {The Eurographics Association},
    ISBN = {978-3-03868-251-6},
    doi = {10.2312/evs.20241074},
    paperurl = {Pron2024Comparative.pdf},
    video = {https://www.youtube.com/watch?v=QxqrSmLa_9E},
    image = {Pron2024Comparative.png}
}
    @PhdThesis{Agarwal2023Dissertation,
    author = 	{Agarwal, Shivam},
    journal = {PhD Dissertation},
    title = 	{Exploring Complex Group Dynamics: Visual Analysis of Overlapping Groups and Interactions Over Time},
    year = 	{2023},
    abstract = 	{Analyzing group dynamics is crucial to understand the behaviors of members in groups. The analysis could help answer important questions: How does the relationship between group members change over time? What is the effect of an action of a member on others? How do group members coordinate their efforts to achieve a goal? What are the overall changes in group behaviors over time? This thesis proposes novel techniques for visually exploring group dynamics, thereby aiding in answering such questions. The proposed techniques apply to diverse scenarios, as demonstrated through application examples. This work focuses on the two characteristic features of group dynamics. First, since members can belong to multiple groups simultaneously, it results in overlaps between groups. We propose two novel visualizations to analyze dynamic memberships in overlapping groups. Their effectiveness is demonstrated by insights from application examples, e.g., authors evolving research interests, classification models performance in their training process, and developer contributions in software repositories. Second, the interactions among group members. A design and application space is proposed to explore user behaviors from mixed reality sessions. Three visualizations are presented to investigate collaborative and competitive interactions among members. The studied scenarios include humans interacting in mixed reality and autonomous agents collaborating and competing in simulated environments. We propose an example of an integrated visual representation to show dynamic memberships in overlapping groups and entity interactions. The thesis discusses the future possibilities in encoding enriched interactions and describes a few works in progress. Finally, the thesis summarizes the contributions, highlights the limitations of the proposed visualizations, and presents a brief outlook toward the future.},
    doi = 	{10.17185/duepublico/81425},
    url = 	{https://doi.org/10.17185/duepublico/81425},
    paperurl = 	{},
    slides = {Agarwal2023Dissertation_Slides.pdf},
    image = {Agarwal2023Dissertation.png},
    video = {https://www.youtube.com/watch?v=fV12Zylg9xM},
    shorturl = {dissertation}
}