<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <link rel="icon" type="image/svg+xml" href="/logo.svg">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&amp;display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Start Single Page Apps for GitHub Pages -->
    <script type="text/javascript">
      (function (l) {
        if (l.search[1] === '/') {
          var decoded = l.search
            .slice(1)
            .split('&')
            .map(function (s) {
              return s.replace(/~and~/g, '&');
            })
            .join('?');
          window.history.replaceState(null, null, l.pathname.slice(0, -1) + decoded + l.hash);
        }
      })(window.location);
    </script>
    <!-- End Single Page Apps for GitHub Pages -->

    <!-- Specific Hash URL Redirects -->
    <script type="text/javascript">
      (function () {
        // Map of specific hash URLs to their clean URL destinations
        var hashRedirectMap = {
          '#/publications': '/publications',
          '#/publications/': '/publications/', // Handle trailing slash version
          '#/publication/': '/publication/', // This will be a prefix match for publication URLs
          // '#/docs': '/docs',
          // Add more specific redirects as needed
        };

        // Get the current hash
        var hash = window.location.hash;
        console.log('Current hash:', hash); // Debug log

        // Check if this hash is in our redirect map
        if (hash) {
          // First check for exact matches
          if (hashRedirectMap[hash]) {
            console.log('Exact match found, redirecting to:', hashRedirectMap[hash]); // Debug log
            window.location.replace(window.location.origin + hashRedirectMap[hash]);
          }
          // Then check for prefix matches (for dynamic routes like publications)
          else {
            var matchFound = false;
            for (var prefix in hashRedirectMap) {
              if (hash.startsWith(prefix) && prefix.endsWith('/')) {
                var cleanPrefix = hashRedirectMap[prefix];
                var suffix = hash.substring(prefix.length);
                var redirectUrl = window.location.origin + cleanPrefix + suffix;
                console.log('Prefix match found, redirecting to:', redirectUrl); // Debug log
                window.location.replace(redirectUrl);
                matchFound = true;
                break;
              }
            }

            // If no match found but starts with #/, use the path directly
            if (!matchFound && hash.startsWith('#/')) {
              var cleanPath = hash.substring(1); // Remove the # character
              console.log('No match found, using direct path:', cleanPath); // Debug log
              window.location.replace(window.location.origin + cleanPath);
            }
          }
        }
      })();
    </script>
    <!-- End Specific Hash URL Redirects -->

    <title>Shivam Agarwal's Website - Data and AI Expert</title>
    <meta name="description" content="This is the website of Shivam Agarwal showcasing the portfolio of his work in data and AI.">
    <meta name="keywords" content="academic, research, publications, papers, scholarly work">
    <meta name="author" content="Shivam Agarwal">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <meta name="google-site-verification" content="L1QbO4CPLDpC06G3v_ZLEhlomt9fj0Vlj9DV_nCqGfc">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://s-agarwl.github.io/publications/Liebers2023Viscomet">
    <meta property="og:title" content="Shivam Agarwal's Website - Data and AI Expert">
    <meta property="og:description" content="This is the website of Shivam Agarwal showcasing the portfolio of his work in data and AI.">
    <meta property="og:image" content="https://s-agarwl.github.io/logo.svg">

    <!-- Publication-specific metadata -->
    <meta name="citation_doi" content="10.1111/cgf.14819">
    <meta name="DC.identifier" content="doi:10.1111/cgf.14819">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://s-agarwl.github.io/publications/Liebers2023Viscomet">
    <meta property="twitter:title" content="Shivam Agarwal's Website - Data and AI Expert">
    <meta property="twitter:description" content="This is the website of Shivam Agarwal showcasing the portfolio of his work in data and AI.">
    <meta property="twitter:image" content="https://s-agarwl.github.io/logo.svg">

    <!-- Google Analytics -->
    
    <!-- Google Analytics -->
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8CMNGL0EH7"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag('js', new Date());
      gtag('config', 'G-8CMNGL0EH7', {
        custom_map: {
          dimension1: 'paper_title',
          dimension2: 'paper_authors',
          dimension3: 'paper_year',
        },
      });
    </script>
  
    <script type="module" crossorigin="" src="/assets/index-qDljs7Wr.js"></script>
    <link rel="stylesheet" crossorigin="" href="/assets/index-Cu9f_Gt2.css">
  <link rel="canonical" href="https://s-agarwl.github.io/publications/Liebers2023Viscomet"><meta property="DC.language" content="en"><script type="application/ld+json">{"@context":"https://schema.org","@type":"ScholarlyArticle","description":""}</script><script id="publication-data" type="application/json">{"entry":{"citationKey":"Liebers2023Viscomet","entryType":"article","entryTags":{"title":"VisCoMET: Visually Analyzing Team Collaboration in Medical Emergency Trainings","author":"Carina Liebers, Shivam Agarwal, Maximilian Krug, Karola Pitsch, and Fabian Beck","abstract":"Handling emergencies requires efficient and effective collaboration of medical professionals. To analyze their performance, in an application study, we have developed VisCoMET, a visual analytics approach displaying interactions of healthcare personnel in a triage training of a mass casualty incident. The application scenario stems from social interaction research, where the collaboration of teams is studied from different perspectives. We integrate recorded annotations from multiple sources, such as recorded videos of the sessions, transcribed communication, and eye-tracking information. For each session, an information-rich timeline visualizes events across these different channels, specifically highlighting interactions between the team members. We provide algorithmic support to identify frequent event patterns and to search for user-defined event sequences. Comparing different teams, an overview visualization aggregates each training session in a visual glyph as a node, connected to similar sessions through edges. An application example shows the usage of the approach in the comparative analysis of triage training sessions, where multiple teams encountered the same scene, and highlights discovered insights. The approach was evaluated through feedback from visualization and social interaction experts. The results show that the approach supports reflecting on teams performance by exploratory analysis of collaboration behavior while particularly enabling the comparison of triage training sessions.","journal":"Computer Graphics Forum","volume":"42","number":"3","pages":"149-160","year":"2023","ISSN":"1467-8659","doi":"10.1111/cgf.14819","data_type":"Event Sequences, Multimodal Data, Interaction Data","application_domain":"Medical Training, Triage, Group Dynamics, Pattern Discovery","visualization_type":"Timeline Visualization, Glyph-based Visualization, Graph Visualization, Visual Comparison, Hybrid Visualization","paperurl":"/publications/Liebers2023Viscomet/Liebers2023Viscomet.pdf","image":"/publications/Liebers2023Viscomet/Liebers2023Viscomet.PNG","video":"https://onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1111%2Fcgf.14819&file=cgf14819-sup-0001.mp4"},"contentType":"publications","sectionPath":"/publications"},"config":{"site":{"title":"Shivam Agarwal's Website - Data and AI Expert","description":"This is the website of Shivam Agarwal showcasing the portfolio of his work in data and AI.","baseUrl":"https://s-agarwl.github.io","googleAnalyticsId":"G-8CMNGL0EH7","keywords":"academic, research, publications, papers, scholarly work","author":"Shivam Agarwal","googleSiteVerification":"L1QbO4CPLDpC06G3v_ZLEhlomt9fj0Vlj9DV_nCqGfc"},"sections":[{"id":"profile","title":"Profile","path":"/"},{"id":"publications","title":"Publications","path":"/publications","dataSource":"/data/pubs.bib","dataType":"bibtex"},{"id":"projects","title":"Projects","path":"/projects","dataSource":"/data/projects.json"},{"id":"mentorships","title":"Mentorships","path":"/mentorships","dataSource":"/mentorship/mentorship.json"},{"id":"my-story","title":"My Story","path":"/my-story"}]},"sectionConfig":{"id":"publications","path":"/publications","title":"Publications","sectionHeading":"Publications","template":"listOfItems","description":"Explore the collection of my publications. From groundbreaking research to practical applications, they reflect my passion for <b>unraveling complex datasets</b>, <b>visual analytics</b>, and <b>advancing AI understanding</b>.","dataSource":"/data/pubs.bib","dataType":"bibtex","bibtexFieldConfig":{"arrayFields":["keywords","data_type","application_domain","analysis_focus","visualization_type","test"],"arraySeparator":",","dateFields":["year","date"],"linkFields":["url","paperurl","slides","video","supplementary","demo","github","poster"],"additionalCitationFields":[]},"overviewVisualization":{"type":"KeywordCloud","enabled":true,"sourceFields":[{"field":"application_domain","label":"Application Domain"},{"field":"visualization_type","label":"Visualization Type"},{"field":"data_type","label":"Data Type"}],"fontSizes":{"min":11,"max":22},"maxVisibleKeywords":15},"display":{"list":{"fields":[{"field":"title","typeOfField":"Heading"},{"field":"authors","typeOfField":"AuthorList","label":"Authors"},{"field":"journal","typeOfField":"Text","variant":"italics_list"},{"field":"booktitle","typeOfField":"Text","variant":"italics_list"},{"field":"application_domain","typeOfField":"Tags","label":"Application Domain"},{"field":"visualization_type","typeOfField":"Tags","label":"Visualization Type"},{"field":"data_type","typeOfField":"Tags","label":"Data Type"},{"field":"awards","typeOfField":"Award"}],"showImage":true},"card":{"fields":[{"field":"title","typeOfField":"Heading","options":{"level":3}},{"field":"links","typeOfField":"PublicationLinks","options":{"showText":true}},{"field":"authors","typeOfField":"AuthorList","label":"Authors"},{"field":"year","typeOfField":"Text","label":"Year"},{"field":"abstract","typeOfField":"ExpandableMarkdown","options":{"limit":10},"label":"Abstract"},{"field":"application_domain","typeOfField":"Tags","label":"Application Domain"},{"field":"visualization_type","typeOfField":"Tags","label":"Visualization Type"},{"field":"data_type","typeOfField":"Tags","label":"Data Type"},{"field":"awards","typeOfField":"Award"}],"showImage":true},"detail":{"fields":[{"field":"title","typeOfField":"Heading","options":{"level":1}},{"field":"image","typeOfField":"Image"},{"field":"awards","typeOfField":"Award"},{"field":"authors","typeOfField":"AuthorList","label":"Authors"},{"field":"year","typeOfField":"Text","label":"Year"},{"field":"journal","typeOfField":"Text","label":"Venue","variant":"italics_detail"},{"field":"booktitle","typeOfField":"Text","label":"Venue","variant":"italics_detail"},{"field":"links","typeOfField":"PublicationLinks","options":{"showText":true}},{"field":"abstract","typeOfField":"ExpandableMarkdown","label":"Abstract","options":{"limit":30}},{"field":"application_domain","typeOfField":"Tags","label":"Application Domain"},{"field":"visualization_type","typeOfField":"Tags","label":"Visualization Type"},{"field":"data_type","typeOfField":"Tags","label":"Data Type"}],"actions":[{"type":"BibTeX","condition":"entryType"},{"type":"Video","condition":"links.video"}]}}}}</script></head>
  <body>
    <div id="prerendered-content"><h1>VisCoMET: Visually Analyzing Team Collaboration in Medical Emergency Trainings</h1><div class="metadata"><p><strong>Year: </strong>2023</p><p><strong>Journal: </strong>Computer Graphics Forum</p><p><strong>Authors: </strong>Carina Liebers, Shivam Agarwal, Maximilian Krug, Karola Pitsch, and Fabian Beck</p><p><strong>DOI: </strong><a href="https://doi.org/10.1111/cgf.14819" target="_blank" rel="noopener noreferrer">10.1111/cgf.14819</a></p></div><h3>Abstract</h3><div class="markdown-content">Handling emergencies requires efficient and effective collaboration of medical professionals. To analyze their performance, in an application study, we have developed VisCoMET, a visual analytics approach displaying interactions of healthcare personnel in a triage training of a mass casualty incident. The application scenario stems from social interaction research, where the collaboration of teams is studied from different perspectives. We integrate recorded annotations from multiple sources, such as recorded videos of the sessions, transcribed communication, and eye-tracking information. For each session, an information-rich timeline visualizes events across these different channels, specifically highlighting interactions between the team members. We provide algorithmic support to identify frequent event patterns and to search for user-defined event sequences. Comparing different teams, an overview visualization aggregates each training session in a visual glyph as a node, connected to similar sessions through edges. An application example shows the usage of the approach in the comparative analysis of triage training sessions, where multiple teams encountered the same scene, and highlights discovered insights. The approach was evaluated through feedback from visualization and social interaction experts. The results show that the approach supports reflecting on teams performance by exploratory analysis of collaboration behavior while particularly enabling the comparison of triage training sessions.</div><h2>Citation</h2><pre><code class="language-bibtex">@article{Liebers2023Viscomet,
  author     = {Carina Liebers, Shivam Agarwal, Maximilian Krug, Karola Pitsch, and Fabian Beck},
  title      = {VisCoMET: Visually Analyzing Team Collaboration in Medical Emergency Trainings},
  journal    = {Computer Graphics Forum},
  volume     = {42},
  number     = {3},
  pages      = {149-160},
  year       = {2023},
  doi        = {10.1111/cgf.14819},
  paperurl   = {/publications/Liebers2023Viscomet/Liebers2023Viscomet.pdf},
  abstract   = {Handling emergencies requires efficient and effective collaboration of medical professionals. To analyze their performance, in an application study, we have developed VisCoMET, a visual analytics approach displaying interactions of healthcare personnel in a triage training of a mass casualty incident. The application scenario stems from social interaction research, where the collaboration of teams is studied from different perspectives. We integrate recorded annotations from multiple sources, such as recorded videos of the sessions, transcribed communication, and eye-tracking information. For each session, an information-rich timeline visualizes events across these different channels, specifically highlighting interactions between the team members. We provide algorithmic support to identify frequent event patterns and to search for user-defined event sequences. Comparing different teams, an overview visualization aggregates each training session in a visual glyph as a node, connected to similar sessions through edges. An application example shows the usage of the approach in the comparative analysis of triage training sessions, where multiple teams encountered the same scene, and highlights discovered insights. The approach was evaluated through feedback from visualization and social interaction experts. The results show that the approach supports reflecting on teams performance by exploratory analysis of collaboration behavior while particularly enabling the comparison of triage training sessions.}
}</code></pre></div><div id="root"></div>

  

</body></html>