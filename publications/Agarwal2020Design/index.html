<!DOCTYPE html><html lang="en"><head>
    <meta charset="UTF-8">
    <link rel="icon" type="image/svg+xml" href="/logo.svg">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&amp;display=swap" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Start Single Page Apps for GitHub Pages -->
    <script type="text/javascript">
      (function (l) {
        if (l.search[1] === '/') {
          var decoded = l.search
            .slice(1)
            .split('&')
            .map(function (s) {
              return s.replace(/~and~/g, '&');
            })
            .join('?');
          window.history.replaceState(null, null, l.pathname.slice(0, -1) + decoded + l.hash);
        }
      })(window.location);
    </script>
    <!-- End Single Page Apps for GitHub Pages -->

    <!-- Specific Hash URL Redirects -->
    <script type="text/javascript">
      (function () {
        // Map of specific hash URLs to their clean URL destinations
        var hashRedirectMap = {
          '#/publications': '/publications',
          '#/publications/': '/publications/', // Handle trailing slash version
          '#/publication/': '/publication/', // This will be a prefix match for publication URLs
          // '#/docs': '/docs',
          // Add more specific redirects as needed
        };

        // Get the current hash
        var hash = window.location.hash;
        console.log('Current hash:', hash); // Debug log

        // Check if this hash is in our redirect map
        if (hash) {
          // First check for exact matches
          if (hashRedirectMap[hash]) {
            console.log('Exact match found, redirecting to:', hashRedirectMap[hash]); // Debug log
            window.location.replace(window.location.origin + hashRedirectMap[hash]);
          }
          // Then check for prefix matches (for dynamic routes like publications)
          else {
            var matchFound = false;
            for (var prefix in hashRedirectMap) {
              if (hash.startsWith(prefix) && prefix.endsWith('/')) {
                var cleanPrefix = hashRedirectMap[prefix];
                var suffix = hash.substring(prefix.length);
                var redirectUrl = window.location.origin + cleanPrefix + suffix;
                console.log('Prefix match found, redirecting to:', redirectUrl); // Debug log
                window.location.replace(redirectUrl);
                matchFound = true;
                break;
              }
            }

            // If no match found but starts with #/, use the path directly
            if (!matchFound && hash.startsWith('#/')) {
              var cleanPath = hash.substring(1); // Remove the # character
              console.log('No match found, using direct path:', cleanPath); // Debug log
              window.location.replace(window.location.origin + cleanPath);
            }
          }
        }
      })();
    </script>
    <!-- End Specific Hash URL Redirects -->

    <title>Shivam Agarwal's Website - Data and AI Expert</title>
    <meta name="description" content="This is the website of Shivam Agarwal showcasing the portfolio of his work in data and AI.">
    <meta name="keywords" content="academic, research, publications, papers, scholarly work">
    <meta name="author" content="Shivam Agarwal">
    <meta name="robots" content="index, follow">
    <meta name="googlebot" content="index, follow">
    <meta name="google-site-verification" content="L1QbO4CPLDpC06G3v_ZLEhlomt9fj0Vlj9DV_nCqGfc">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://s-agarwl.github.io/publications/Agarwal2020Design">
    <meta property="og:title" content="Shivam Agarwal's Website - Data and AI Expert">
    <meta property="og:description" content="This is the website of Shivam Agarwal showcasing the portfolio of his work in data and AI.">
    <meta property="og:image" content="https://s-agarwl.github.io/logo.svg">

    <!-- Publication-specific metadata -->
    <meta name="citation_doi" content="doi:10.2312/vmv.20201194">
    <meta name="DC.identifier" content="doi:doi:10.2312/vmv.20201194">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://s-agarwl.github.io/publications/Agarwal2020Design">
    <meta property="twitter:title" content="Shivam Agarwal's Website - Data and AI Expert">
    <meta property="twitter:description" content="This is the website of Shivam Agarwal showcasing the portfolio of his work in data and AI.">
    <meta property="twitter:image" content="https://s-agarwl.github.io/logo.svg">

    <!-- Google Analytics -->
    
    <!-- Google Analytics -->
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8CMNGL0EH7"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag('js', new Date());
      gtag('config', 'G-8CMNGL0EH7', {
        custom_map: {
          dimension1: 'paper_title',
          dimension2: 'paper_authors',
          dimension3: 'paper_year',
        },
      });
    </script>
  
    <script type="module" crossorigin="" src="/assets/index-DNl5wTNa.js"></script>
    <link rel="stylesheet" crossorigin="" href="/assets/index-Cu9f_Gt2.css">
  <link rel="canonical" href="https://s-agarwl.github.io/publications/Agarwal2020Design"><meta property="DC.language" content="en"><script type="application/ld+json">{"@context":"https://schema.org","@type":"ScholarlyArticle","description":""}</script><script id="publication-data" type="application/json">{"entry":{"citationKey":"Agarwal2020Design","entryType":"inproceedings","entryTags":{"type":"Full Paper","title":"A Design and Application Space for Visualizing User Sessions of Virtual and Mixed Reality Environments","booktitle":"Vision, Modeling, and Visualization","doi":"doi:10.2312/vmv.20201194","abstract":"Virtual and mixed reality environments gain complexity due to the inclusion of multiple users and physical objects. A core challenge for developers and researchers while analyzing sessions from such environments lies in understanding the interaction between entities. Additionally, the raw data recorded from such sessions is difficult to analyze due to the simultaneous temporal and spatial changes of multiple entities. However, similar data has already been visualized in other areas of application. We analyze which aspects of these related visualizations can be leveraged for analyzing user sessions in virtual and mixed reality environments and describe a design and application space for such visualizations. First, we examine what information is typically generated in interactive virtual and mixed reality applications and how it can be analyzed through such visualizations. Next, we study visualizations from related research fields and derive seven visualization categories. These categories act as building blocks of the design space, which can be combined into specific visualization systems. We also discuss the application space for these visualizations in debugging and evaluation scenarios. We present two application examples that showcase how one can visualize virtual and mixed reality user sessions and derive useful insights from them.","url":"https://dx.doi.org/doi:10.2312/vmv.20201194","year":"2020","month":"sep","author":"Shivam Agarwal, Jonas Auda, Stefan Schneegaß, and Fabian Beck","data_type":"Spatio-Temporal Data, Interaction Data","application_domain":"Virtual Reality, Mixed Reality, Group Dynamics","visualization_type":"Timeline Visualization, Heatmap Visualization, Glyph-based Visualization, Multiple Visualization Types","paperurl":"/publications/Agarwal2020Design/Agarwal2020Design.pdf","video":"https://www.youtube.com/watch?v=hUenXnU5Adk","image":"/publications/Agarwal2020Design/Agarwal2020Design.PNG","demo":"https://vis-uni-bamberg.github.io/vr_mr_vis/","supplementary":"https://osf.io/2hstc/","github":"https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/vr_mr_vis","shorturl":"mrsessions"},"contentType":"publications","sectionPath":"/publications"},"config":{"site":{"title":"Shivam Agarwal's Website - Data and AI Expert","description":"This is the website of Shivam Agarwal showcasing the portfolio of his work in data and AI.","baseUrl":"https://s-agarwl.github.io","googleAnalyticsId":"G-8CMNGL0EH7","keywords":"academic, research, publications, papers, scholarly work","author":"Shivam Agarwal","googleSiteVerification":"L1QbO4CPLDpC06G3v_ZLEhlomt9fj0Vlj9DV_nCqGfc"},"sections":[{"id":"profile","title":"Profile","path":"/"},{"id":"publications","title":"Publications","path":"/publications","dataSource":"/data/pubs.bib","dataType":"bibtex"},{"id":"projects","title":"Projects","path":"/projects","dataSource":"/data/projects.json"},{"id":"mentorships","title":"Mentorships","path":"/mentorships","dataSource":"/mentorship/mentorship.json"},{"id":"my-story","title":"My Story","path":"/my-story"}]},"sectionConfig":{"id":"publications","path":"/publications","title":"Publications","sectionHeading":"Publications","template":"listOfItems","description":"Explore the collection of my publications. From groundbreaking research to practical applications, they reflect my passion for <b>unraveling complex datasets</b>, <b>visual analytics</b>, and <b>advancing AI understanding</b>.","dataSource":"/data/pubs.bib","dataType":"bibtex","bibtexFieldConfig":{"arrayFields":["keywords","data_type","application_domain","analysis_focus","visualization_type","test"],"arraySeparator":",","dateFields":["year","date"],"linkFields":["url","paperurl","slides","video","supplementary","demo","github","poster"],"additionalCitationFields":[]},"overviewVisualization":{"type":"KeywordCloud","enabled":true,"sourceFields":[{"field":"application_domain","label":"Application Domain"},{"field":"visualization_type","label":"Visualization Type"},{"field":"data_type","label":"Data Type"}],"fontSizes":{"min":11,"max":22},"maxVisibleKeywords":15},"display":{"list":{"fields":[{"field":"title","typeOfField":"Heading"},{"field":"authors","typeOfField":"AuthorList","label":"Authors"},{"field":"journal","typeOfField":"Text","variant":"italics_list"},{"field":"booktitle","typeOfField":"Text","variant":"italics_list"},{"field":"application_domain","typeOfField":"Tags","label":"Application Domain"},{"field":"visualization_type","typeOfField":"Tags","label":"Visualization Type"},{"field":"data_type","typeOfField":"Tags","label":"Data Type"},{"field":"awards","typeOfField":"Award"}],"showImage":true},"card":{"fields":[{"field":"title","typeOfField":"Heading","options":{"level":3}},{"field":"links","typeOfField":"PublicationLinks","options":{"showText":true}},{"field":"authors","typeOfField":"AuthorList","label":"Authors"},{"field":"year","typeOfField":"Text","label":"Year"},{"field":"abstract","typeOfField":"ExpandableMarkdown","options":{"limit":10},"label":"Abstract"},{"field":"application_domain","typeOfField":"Tags","label":"Application Domain"},{"field":"visualization_type","typeOfField":"Tags","label":"Visualization Type"},{"field":"data_type","typeOfField":"Tags","label":"Data Type"},{"field":"awards","typeOfField":"Award"}],"showImage":true},"detail":{"fields":[{"field":"title","typeOfField":"Heading","options":{"level":1}},{"field":"image","typeOfField":"Image"},{"field":"awards","typeOfField":"Award"},{"field":"authors","typeOfField":"AuthorList","label":"Authors"},{"field":"year","typeOfField":"Text","label":"Year"},{"field":"journal","typeOfField":"Text","label":"Venue","variant":"italics_detail"},{"field":"booktitle","typeOfField":"Text","label":"Venue","variant":"italics_detail"},{"field":"links","typeOfField":"PublicationLinks","options":{"showText":true}},{"field":"abstract","typeOfField":"ExpandableMarkdown","label":"Abstract","options":{"limit":30}},{"field":"application_domain","typeOfField":"Tags","label":"Application Domain"},{"field":"visualization_type","typeOfField":"Tags","label":"Visualization Type"},{"field":"data_type","typeOfField":"Tags","label":"Data Type"}],"actions":[{"type":"BibTeX","condition":"entryType"},{"type":"Video","condition":"links.video"}]}}}}</script></head>
  <body>
    <div id="prerendered-content"><h1>A Design and Application Space for Visualizing User Sessions of Virtual and Mixed Reality Environments</h1><div class="metadata"><p><strong>Year: </strong>2020</p><p><strong>Conference: </strong>Vision, Modeling, and Visualization</p><p><strong>Authors: </strong>Shivam Agarwal, Jonas Auda, Stefan Schneegaß, and Fabian Beck</p><p><strong>DOI: </strong><a href="https://doi.org/doi:10.2312/vmv.20201194" target="_blank" rel="noopener noreferrer">doi:10.2312/vmv.20201194</a></p></div><h3>Abstract</h3><div class="markdown-content">Virtual and mixed reality environments gain complexity due to the inclusion of multiple users and physical objects. A core challenge for developers and researchers while analyzing sessions from such environments lies in understanding the interaction between entities. Additionally, the raw data recorded from such sessions is difficult to analyze due to the simultaneous temporal and spatial changes of multiple entities. However, similar data has already been visualized in other areas of application. We analyze which aspects of these related visualizations can be leveraged for analyzing user sessions in virtual and mixed reality environments and describe a design and application space for such visualizations. First, we examine what information is typically generated in interactive virtual and mixed reality applications and how it can be analyzed through such visualizations. Next, we study visualizations from related research fields and derive seven visualization categories. These categories act as building blocks of the design space, which can be combined into specific visualization systems. We also discuss the application space for these visualizations in debugging and evaluation scenarios. We present two application examples that showcase how one can visualize virtual and mixed reality user sessions and derive useful insights from them.</div><h2>Citation</h2><pre><code class="language-bibtex">@inproceedings{Agarwal2020Design,
  author     = {Shivam Agarwal, Jonas Auda, Stefan Schneegaß, and Fabian Beck},
  title      = {A Design and Application Space for Visualizing User Sessions of Virtual and Mixed Reality Environments},
  booktitle  = {Vision, Modeling, and Visualization},
  year       = {2020},
  month      = {sep},
  doi        = {doi:10.2312/vmv.20201194},
  url        = {https://dx.doi.org/doi:10.2312/vmv.20201194},
  paperurl   = {/publications/Agarwal2020Design/Agarwal2020Design.pdf},
  github     = {https://github.com/vis-uni-bamberg/vis-uni-bamberg.github.io/tree/main/vr_mr_vis},
  demo       = {https://vis-uni-bamberg.github.io/vr_mr_vis/},
  abstract   = {Virtual and mixed reality environments gain complexity due to the inclusion of multiple users and physical objects. A core challenge for developers and researchers while analyzing sessions from such environments lies in understanding the interaction between entities. Additionally, the raw data recorded from such sessions is difficult to analyze due to the simultaneous temporal and spatial changes of multiple entities. However, similar data has already been visualized in other areas of application. We analyze which aspects of these related visualizations can be leveraged for analyzing user sessions in virtual and mixed reality environments and describe a design and application space for such visualizations. First, we examine what information is typically generated in interactive virtual and mixed reality applications and how it can be analyzed through such visualizations. Next, we study visualizations from related research fields and derive seven visualization categories. These categories act as building blocks of the design space, which can be combined into specific visualization systems. We also discuss the application space for these visualizations in debugging and evaluation scenarios. We present two application examples that showcase how one can visualize virtual and mixed reality user sessions and derive useful insights from them.}
}</code></pre></div><div id="root"></div>

  

</body></html>